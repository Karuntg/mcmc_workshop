{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability concept review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please read over this page before the first session! If you have any questions about the concepts presented here, please ask :)\n",
    "\n",
    "## Contents\n",
    "1. [Probability laws review](#prob_laws)\n",
    "2. [Introduction to Bayes Theorem and terminology](#intro_bayes)\n",
    "3. [Resources for workshop](#resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Probability laws review <a id='prob_laws'></a>\n",
    "\n",
    "Here are some introductory concepts and definitions that will be helpful to remember. If you have taken a probability or statistics class, you will probably already seen these. So this is just a friendly reminder.\n",
    "\n",
    "1. Since different places use different symbols and terminology, here's a review to ensure we're on the same page:\n",
    "    - A **discrete random variable** is a variable with a finite number of possible outcomes, such as: the number of heads in 10 coin flips, number of people registered for a class, or the number of planets in an exoplanet system etc.\n",
    "    - A **continuous random variable** is a variable that can take a continuous range of values, such as: the height of a random person, the mass of a Galaxy, or the semi-major axis of a planet's orbbit, etc.\n",
    "    - \n",
    "\n",
    "\n",
    "1.  For a case where there are $N$ possible outcomes (let's call them $A$, $B$, etc.), we can say the following.\n",
    "    - $P(A)$ means the probability of outcome $A$ happening. This value is always between 0 and 1 (in the *discrete* case)\n",
    "    - The probability of all $N$ outcomes must sum up to 1. So if only outcomes $A$ and $B$ are possible, then by definition, $$\\mathrm{prob}(B) = 1 - \\mathrm{prob}(A).$$\n",
    "    - Similarly, if you are only considering whether or not outcome $A$ happened, then the two possibilities are \"$A$ happened\" and \"$A$ didn't happen\", which we can write as \"$A$\" and \"not $A$\", and by definition, \n",
    "    $$\\mathrm{prob}(A) + \\mathrm{prob}(\\mathrm{not}\\ A) = 1.$$\n",
    "\n",
    "2. A **continuous random variable** is a variable \n",
    "\n",
    "3. With two events, we might be interested in whether one or the other has happened. In general, the probability that $A$ **or** $B$ happened is\n",
    "    $$\\mathrm{prob}(A\\ \\mathrm{or}\\ B) = \\mathrm{prob}(A) + \\mathrm{prob}(B) - \\mathrm{prob}(A\\ \\mathrm{and}\\ B).$$\n",
    "    Here, \"or\" usually means the \"inclusive or\". We have to subtract the third term because we don't want to double-count cases where both $A$ and $B$ happen. In special cases where $A$ and $B$ are \"disjoint\" (i.e. they can't both be true, such as $A$ being a coin flip resulting in heads and $B$ being a coin flip resulting in tails), you can drop the third term since $\\mathrm{prob}(A\\ \\mathrm{and}\\ B) = 0.$\n",
    "\n",
    "\n",
    "5. $\\mathrm{prob}(A|B)$ means the probability of outcome $A$ happening, given that outcome $B$ already happened. If $A$ and $B$ are independent of each other, then $\\mathrm{prob}(A|B) = \\mathrm{prob}(A)$ since independence means that the likelihood of A is the same no matter if B happened or not.\n",
    "\n",
    "\n",
    "6. With two events, we might be interested in whether both happens. In general, the probability that $A$ **and** $B$ happened is\n",
    "    $$\\mathrm{prob}(A\\ \\mathrm{and}\\ B) = \\mathrm{prob}(A) * \\mathrm{prob}(B|A).$$\n",
    "    - This is the probability of A happening multiplied by the probability of $B$ happening given that $A$ already happened. Note that there's no special order to $A$ and $B$, therefore, you can also say\n",
    "    $$\\mathrm{prob}(A\\ \\mathrm{and}\\ B) = \\mathrm{prob}(B) * \\mathrm{prob}(A|B).$$\n",
    "    - This leads to the useful equality/identity\n",
    "    $$\\mathrm{prob}(A) * \\mathrm{prob}(B|A) = \\mathrm{prob}(B) * \\mathrm{prob}(A|B).$$\n",
    "    - And, in the special case where $A$ and $B$ are independent of each other, then\n",
    "    $\\mathrm{prob}(A\\ \\mathrm{and}\\ B) = prob(A) * prob(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to Bayes Theorem and terminology <a id='intro_bayes'></a>\n",
    "\n",
    "We can now introduce Bayes' theorem and the basis for our Bayesian inference framework.\n",
    "\n",
    "Bayes Theorem can be stated as an equation\n",
    "\n",
    "$$\\mathrm{prob}(M|D) = \\frac{\\mathrm{prob}(D|M) * \\mathrm{prob}(M)}{\\mathrm{prob}(D)}.$$\n",
    "\n",
    "Here, I am using $M$ to mean \"the model\" and $D$ to mean \"the data\". When we say \"the model\" we include all the parameters that describe the model. When we say \"the data\" we include all of the measurements and uncertainties/errorbars with those measurements. If we put this in words, we're saying:\n",
    "\n",
    "- $\\mathrm{prob}(M | D)$  is $\\mathrm{prob}($our model is right, given the data we measured$)$,\n",
    "- $\\mathrm{prob}(D | M)$ is $\\mathrm{prob}($getting measured data, given the model$)$,\n",
    "- $\\mathrm{prob}(M)$ is $\\mathrm{prob}($the model is right [without consideration to any data]$)$, and\n",
    "- $\\mathrm{prob}(D)$ is $\\mathrm{prob}($of the data$)$.\n",
    "\n",
    "In Bayesian-speak, these terms are often called:\n",
    "\n",
    "- $\\mathrm{prob} (M | D)$ is the **posterior probability** on $M$\n",
    "- $\\mathrm{prob} (D | M)$ is the **likelihood**\n",
    "- $\\mathrm{prob} (M)$ is the **prior probability** on $M$\n",
    "- $\\mathrm{prob} (D)$ is the **evidence** \n",
    "- Warning: many different fields / books / websites use different names for these same things and some even switch them!\n",
    "\n",
    "So if you look at the definitions and the equations again,there is a flow. We start with some initial prior probability on $M$, $\\mathrm{prob}(M)$. Bayes Theorem is an equation to get a posterior probability on $M$, $\\mathrm{prob}(M|D)$ if we have some data, and we do that using the likelihood $\\mathrm{prob}(D|M)$ term. \n",
    "\n",
    "In normal practice, we choose a prior probability distribution for $M$, and we know how to calculate $\\mathrm{prob}(D|M)$ (e.g. through least squares), so we use Bayes Theorem to compute $\\mathrm{prob}(M|D)$. Then, we can repeat this cycle when we have more data: The answer from last time is the prior probability and the new data lets us \"update\" our posterior.\n",
    "\n",
    "This is the whole point of Bayesian inference and this concept of \"updating our probabilities\" is one of the key concepts of the \"philosophy\" of Bayesian inference (as compared to other models for computing probabilities and statistics, such as frequentist stats).\n",
    "\n",
    "As humans, we naturally apply these Bayesian concepts. One example: growing up in Richmond, I knew that cloudy skies in the morning means a high chance of rain that day so I would bring an umbrella. When I moved to Pasadena, I started preparing for rain whenever the morning started cloudy (i.e. my \"model\"). However, I soon experienced that it almost never rains in Pasadena and every cloudy morning became bright sun in the afternoon (i.e. \"new data\"). So, using this new data, I updated my model and stopped preparing for rain whenever it was cloudy in the morning! \n",
    "\n",
    "If you're paying attention, we have ignored the \"evidence\" term completely. For this workshop, we can ignore it because the evidence term is $\\mathrm{prob}(D)$ which does not depend on the model parameters at all. We can treat it like a normalizing constant in Bayes Theorem for the purposes of this workshop. That is, we will only see how the posterior probability varies when the model parameters change, so we can \"cancel out\" this term, or basically just compute $\\mathrm{prob}(M|D) \\propto \\mathrm{prob}(D|M) * \\mathrm{prob}(M).$ We will need this evidence term when doing something more advanced where we need the absolute value of the posterior probability, such as comparing between different types of models. But that is outside the scope of this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resources for workshop <a id='resources'></a>\n",
    "\n",
    "No need to read these before the workshop, just wanted to provide references in case you want to review materials at a later date.\n",
    "\n",
    "### \"Data Analysis: A Bayesian Tutorial, 2nd edition\" by D. S. Sivia \n",
    "\n",
    "I really like how this book presents Bayesian inference ideas and also the equations/math is accessible (i.e. it's written with an audience like us in mind, rather than a series of proofs!)\n",
    "\n",
    "It turns out you can get this book online, for free, from the UVic Library: http://voyager.library.uvic.ca/vwebv/holdingsInfo?searchId=3384&recCount=25&recPointer=0&bibId=1761051\n",
    "\n",
    "In this workshop, we will be using concepts from the first two chapters only, primarily drawing on the introductory material in Chapter 1 and some examples in Chapter 2. It does not cover MCMC.\n",
    "\n",
    "### \"Markov Chain Monte Carlo\", Chapter 15.8 in \"Numerical Recipes: The Art of Scientific Computing, 3rd Edition\" by Press et al. (2007), pp. 824-836\n",
    "\n",
    "If you have a copy of this book or can find this book chapter/subsection, it would be a nice companion to our workshop. But you won't need it to do the workshop, it's just a handy reference.\n",
    "\n",
    "\n",
    "### \"Markov Chain Monte Carlo Without all the Bullshit\", Jeremy Kun, *Math $\\cap$ Programming* blog post\n",
    "\n",
    "A brief introduction that I recently learned about which does what its title promises!  \n",
    "\n",
    "https://jeremykun.com/2015/04/06/markov-chain-monte-carlo-without-all-the-bullshit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
